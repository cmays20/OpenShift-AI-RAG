{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "%pip install kaggle kagglehub plotly numpy pandas pillow matplotlib opencv-python ipywidgets ultralytics albumentations boto3\n",
    "\n",
    "from IPython import display\n",
    "display.clear_output()\n",
    "!yolo checks"
   ],
   "id": "f05ed97e5767f69"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"airbusgeo/airbus-aircrafts-sample-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ],
   "id": "df5d047710b85395"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import ast\n",
    "import PIL\n",
    "from pathlib import Path\n",
    "import random\n",
    "import cv2\n",
    "import os\n",
    "import boto3\n",
    "\n",
    "import matplotlib\n",
    "%matplotlib inline"
   ],
   "id": "37832b3b21de774"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "DATA_DIR = Path(path)\n",
    "img_list = list(DATA_DIR.glob('images/*.jpg'))\n",
    "pickone = random.choice(img_list)\n",
    "display.Image(pickone)"
   ],
   "id": "7b841899cd17f15e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "print(f\"Found {len(img_list)} images files in {DATA_DIR}\")\n",
    "\n",
    "img = PIL.Image.open(pickone)\n",
    "IMAGE_HEIGHT, IMAGE_WIDTH = img.size\n",
    "num_channels = len(img.mode)\n",
    "print(\"Image size: {}\".format((IMAGE_HEIGHT, IMAGE_WIDTH)))\n",
    "print(\"Num channels: {}\".format(num_channels))"
   ],
   "id": "8d6745a91f1df6df"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "df = pd.read_csv(DATA_DIR / 'annotations.csv')\n",
    "# convert a string record into a valid python object\n",
    "def f(x):\n",
    "    return ast.literal_eval(x.rstrip('\\r\\n'))\n",
    "\n",
    "df = pd.read_csv(DATA_DIR / \"annotations.csv\",\n",
    "                converters={'geometry': f})\n",
    "df.head(10)"
   ],
   "id": "6a21c96a93b90eba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def getBounds(geometry):\n",
    "    try:\n",
    "        arr = np.array(geometry).T\n",
    "        xmin = np.min(arr[0])\n",
    "        ymin = np.min(arr[1])\n",
    "        xmax = np.max(arr[0])\n",
    "        ymax = np.max(arr[1])\n",
    "        return (xmin, ymin, xmax, ymax)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def getWidth(bounds):\n",
    "    try:\n",
    "        (xmin, ymin, xmax, ymax) = bounds\n",
    "        return np.abs(xmax - xmin)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def getHeight(bounds):\n",
    "    try:\n",
    "        (xmin, ymin, xmax, ymax) = bounds\n",
    "        return np.abs(ymax - ymin)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Create bounds, width and height\n",
    "df.loc[:,'bounds'] = df.loc[:,'geometry'].apply(getBounds)\n",
    "df.loc[:,'width'] = df.loc[:,'bounds'].apply(getWidth)\n",
    "df.loc[:,'height'] = df.loc[:,'bounds'].apply(getHeight)\n",
    "df.head(10)"
   ],
   "id": "59ed4c22709181ae"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# create a list of images used for validation\n",
    "fold = 1\n",
    "num_fold = 5\n",
    "index = df['image_id'].unique()\n",
    "val_indexes = index[len(index)*fold//num_fold:len(index)*(fold+1)//num_fold]\n",
    "print(val_indexes)"
   ],
   "id": "a90bcc5b7cf07380"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import tqdm.notebook\n",
    "\n",
    "# Create 512x512 tiles with 64 pix overlap in /kaggle/working\n",
    "TILE_WIDTH = 512\n",
    "TILE_HEIGHT = 512\n",
    "TILE_OVERLAP = 128\n",
    "TRUNCATED_PERCENT = 0.3\n",
    "_overwriteFiles = True\n",
    "\n",
    "TILES_DIR = {'train': Path('kaggle/working/train/images/'),\n",
    "             'val': Path('kaggle/working/val/images/')}\n",
    "for _, folder in TILES_DIR.items():\n",
    "    if not os.path.isdir(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "LABELS_DIR = {'train': Path('kaggle/working/train/labels/'),\n",
    "              'val': Path('kaggle/working/val/labels/')}\n",
    "for _, folder in LABELS_DIR.items():\n",
    "    if not os.path.isdir(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "# Save one line in .txt file for each tag found inside the tile\n",
    "def tag_is_inside_tile(bounds, x_start, y_start, width, height, truncated_percent):\n",
    "    x_min, y_min, x_max, y_max = bounds\n",
    "    x_min, y_min, x_max, y_max = x_min - x_start, y_min - y_start, x_max - x_start, y_max - y_start\n",
    "\n",
    "    if (x_min > width) or (x_max < 0.0) or (y_min > height) or (y_max < 0.0):\n",
    "        return None\n",
    "\n",
    "    x_max_trunc = min(x_max, width)\n",
    "    x_min_trunc = max(x_min, 0)\n",
    "    if (x_max_trunc - x_min_trunc) / (x_max - x_min) < truncated_percent:\n",
    "        return None\n",
    "\n",
    "    y_max_trunc = min(y_max, height)\n",
    "    y_min_trunc = max(y_min, 0)\n",
    "    if (y_max_trunc - y_min_trunc) / (y_max - y_min) < truncated_percent:\n",
    "        return None\n",
    "\n",
    "    x_center = (x_min_trunc + x_max_trunc) / 2.0 / width\n",
    "    y_center = (y_min_trunc + y_max_trunc) / 2.0 / height\n",
    "    x_extend = (x_max_trunc - x_min_trunc) / width\n",
    "    y_extend = (y_max_trunc - y_min_trunc) / height\n",
    "\n",
    "    return (0, x_center, y_center, x_extend, y_extend)\n",
    "\n",
    "for img_path in tqdm.notebook.tqdm(img_list):\n",
    "    # Open image and related data\n",
    "    pil_img = PIL.Image.open(img_path, mode='r')\n",
    "    np_img = np.array(pil_img, dtype=np.uint8)\n",
    "\n",
    "    # Get annotations for image\n",
    "    img_labels = df[df[\"image_id\"] == img_path.name]\n",
    "    #print(img_labels)\n",
    "\n",
    "    # Count number of sections to make\n",
    "    X_TILES = (IMAGE_WIDTH + TILE_WIDTH + TILE_OVERLAP - 1) // TILE_WIDTH\n",
    "    Y_TILES = (IMAGE_HEIGHT + TILE_HEIGHT + TILE_OVERLAP - 1) // TILE_HEIGHT\n",
    "\n",
    "    # Cut each tile\n",
    "    for x in range(X_TILES):\n",
    "        for y in range(Y_TILES):\n",
    "\n",
    "            x_end = min((x + 1) * TILE_WIDTH - TILE_OVERLAP * (x != 0), IMAGE_WIDTH)\n",
    "            x_start = x_end - TILE_WIDTH\n",
    "            y_end = min((y + 1) * TILE_HEIGHT - TILE_OVERLAP * (y != 0), IMAGE_HEIGHT)\n",
    "            y_start = y_end - TILE_HEIGHT\n",
    "            #print(x_start, y_start)\n",
    "\n",
    "            folder = 'val' if img_path.name in val_indexes else 'train'\n",
    "            save_tile_path = TILES_DIR[folder].joinpath(img_path.stem + \"_\" + str(x_start) + \"_\" + str(y_start) + \".jpg\")\n",
    "            save_label_path = LABELS_DIR[folder].joinpath(img_path.stem + \"_\" + str(x_start) + \"_\" + str(y_start) + \".txt\")\n",
    "\n",
    "            # Save if file doesn't exit\n",
    "            if _overwriteFiles or not os.path.isfile(save_tile_path):\n",
    "                cut_tile = np.zeros(shape=(TILE_WIDTH, TILE_HEIGHT, 3), dtype=np.uint8)\n",
    "                cut_tile[0:TILE_HEIGHT, 0:TILE_WIDTH, :] = np_img[y_start:y_end, x_start:x_end, :]\n",
    "                cut_tile_img = PIL.Image.fromarray(cut_tile)\n",
    "                cut_tile_img.save(save_tile_path)\n",
    "\n",
    "            found_tags = [\n",
    "                tag_is_inside_tile(bounds, x_start, y_start, TILE_WIDTH, TILE_HEIGHT, TRUNCATED_PERCENT)\n",
    "                for i, bounds in enumerate(img_labels['bounds'])]\n",
    "            found_tags = [el for el in found_tags if el is not None]\n",
    "\n",
    "            # save labels\n",
    "            with open(save_label_path, 'w+') as f:\n",
    "                for tags in found_tags:\n",
    "                    f.write(' '.join(str(x) for x in tags) + '\\n')"
   ],
   "id": "80407a5838186365"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "CONFIG = \"\"\"\n",
    "# train and val datasets (image directory or *.txt file with image paths)\n",
    "train: train/\n",
    "val: val/\n",
    "\n",
    "# number of classes\n",
    "nc: 1\n",
    "\n",
    "# class names\n",
    "names: ['Aircraft']\n",
    "\"\"\"\n",
    "\n",
    "with open(\"kaggle/working/data.yaml\", \"w\") as f:\n",
    "    f.write(CONFIG)"
   ],
   "id": "aa9f8af319cde9da"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "HOME = \"kaggle/working/\"\n",
    "!yolo task=detect mode=train model=yolo11s.pt data={HOME}/data.yaml epochs=10 imgsz=512 augment=True auto_augment=True device=0"
   ],
   "id": "ce2eed4de3d41572"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_path = 'runs/detect/train'\n",
    "\n",
    "display.Image(filename=train_path + '/BoxF1_curve.png', width=600)"
   ],
   "id": "fad88395d99e57b3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import pandas as pd\n",
    "pio.renderers.default = 'notebook'\n",
    "\n",
    "df = pd.read_csv(train_path + \"/results.csv\")\n",
    "fig = px.line(df, x='epoch', y='metrics/mAP50(B)', title='mAP50')\n",
    "fig.show()"
   ],
   "id": "b3b763623321198f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "display.Image(filename=train_path + '/val_batch0_pred.jpg', width=1000)",
   "id": "21b00bfd9cfec9d1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "!yolo task=detect mode=val model={train_path}/weights/best.pt data={HOME}/data.yaml device=0",
   "id": "7edf6d3ba54ca4b7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ultralytics import YOLO\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "# Load your trained model\n",
    "model_path = train_path + \"/weights/best.pt\"  # Update this path if needed\n",
    "model = YOLO(model_path)\n",
    "\n",
    "print(f\"(Model loaded)\")"
   ],
   "id": "f393db6c0fd3d62"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Path to your test images folder\n",
    "test_images_path = path + \"/extras\"  # Change this to your test images folder\n",
    "\n",
    "# Get all images in the test folder\n",
    "test_images = [str(p) for p in Path(test_images_path).glob(\"*.jpg\")]\n",
    "print(f\"Found {len(test_images)} test images\")"
   ],
   "id": "6779d299be0f2412"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Tiled Inference for Full-Size Images\n",
    "# This notebook implements sliding window inference to match the training tile size\n",
    "\n",
    "# Configuration - MUST match training parameters\n",
    "TILE_WIDTH = 512\n",
    "TILE_HEIGHT = 512\n",
    "TILE_OVERLAP = 128\n",
    "CONF_THRESHOLD = 0.15\n",
    "NMS_THRESHOLD = 0.8  # Non-maximum suppression for overlapping detections\n",
    "\n",
    "def sliding_window_inference(image_path, model, tile_width=512, tile_height=512, overlap=64, conf_threshold=0.25):\n",
    "    \"\"\"\n",
    "    Perform inference on full-size image using sliding window approach\n",
    "\n",
    "    Args:\n",
    "        image_path: Path to the full-size image\n",
    "        model: Trained YOLO model\n",
    "        tile_width: Width of each tile (should match training)\n",
    "        tile_height: Height of each tile (should match training)\n",
    "        overlap: Overlap between tiles (should match training)\n",
    "        conf_threshold: Confidence threshold for detections\n",
    "\n",
    "    Returns:\n",
    "        List of detections with format: [x1, y1, x2, y2, confidence, class_id]\n",
    "    \"\"\"\n",
    "    # Load the full image\n",
    "    image = Image.open(image_path)\n",
    "    img_width, img_height = image.size\n",
    "    image_np = np.array(image)\n",
    "\n",
    "    print(f\"Processing image: {os.path.basename(image_path)}\")\n",
    "    print(f\"Image size: {img_width}x{img_height}\")\n",
    "\n",
    "    all_detections = []\n",
    "\n",
    "    # Calculate number of tiles needed\n",
    "    x_tiles = (img_width + tile_width - overlap - 1) // (tile_width - overlap)\n",
    "    y_tiles = (img_height + tile_height - overlap - 1) // (tile_height - overlap)\n",
    "\n",
    "    print(f\"Creating {x_tiles}x{y_tiles} = {x_tiles * y_tiles} tiles\")\n",
    "\n",
    "    for y in range(y_tiles):\n",
    "        for x in range(x_tiles):\n",
    "            # Calculate tile boundaries\n",
    "            x_start = x * (tile_width - overlap)\n",
    "            y_start = y * (tile_height - overlap)\n",
    "            x_end = min(x_start + tile_width, img_width)\n",
    "            y_end = min(y_start + tile_height, img_height)\n",
    "\n",
    "            # Extract tile\n",
    "            tile = image_np[y_start:y_end, x_start:x_end]\n",
    "\n",
    "            # Pad tile if necessary to maintain consistent input size\n",
    "            if tile.shape[0] != tile_height or tile.shape[1] != tile_width:\n",
    "                padded_tile = np.zeros((tile_height, tile_width, 3), dtype=np.uint8)\n",
    "                padded_tile[:tile.shape[0], :tile.shape[1]] = tile\n",
    "                tile = padded_tile\n",
    "\n",
    "            # Convert to PIL Image for YOLO\n",
    "            tile_pil = Image.fromarray(tile)\n",
    "\n",
    "            # Run inference on tile\n",
    "            results = model(tile_pil, conf=conf_threshold, verbose=False)\n",
    "\n",
    "            # Process detections from this tile\n",
    "            if len(results[0].boxes) > 0:\n",
    "                boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "                scores = results[0].boxes.conf.cpu().numpy()\n",
    "                classes = results[0].boxes.cls.cpu().numpy()\n",
    "\n",
    "                # Convert tile coordinates to full image coordinates\n",
    "                for box, score, cls in zip(boxes, scores, classes):\n",
    "                    x1, y1, x2, y2 = box\n",
    "\n",
    "                    # Adjust coordinates to full image space\n",
    "                    global_x1 = x1 + x_start\n",
    "                    global_y1 = y1 + y_start\n",
    "                    global_x2 = x2 + x_start\n",
    "                    global_y2 = y2 + y_start\n",
    "\n",
    "                    # Option B: Remove margin completely for center tiles\n",
    "                    if x > 0 and x < x_tiles-1 and y > 0 and y < y_tiles-1:\n",
    "                        # Center tiles - no margin needed\n",
    "                        all_detections.append([global_x1, global_y1, global_x2, global_y2, score, int(cls)])\n",
    "                    else:\n",
    "                        # Edge tiles - small margin to avoid image boundary issues\n",
    "                        margin = 10\n",
    "                        if (x1 > margin and y1 > margin and\n",
    "                            x2 < tile_width - margin and y2 < tile_height - margin):\n",
    "                            all_detections.append([global_x1, global_y1, global_x2, global_y2, score, int(cls)])\n",
    "\n",
    "\n",
    "    print(f\"Found {len(all_detections)} raw detections before NMS\")\n",
    "\n",
    "    # Apply Non-Maximum Suppression to remove duplicate detections\n",
    "    if len(all_detections) > 0:\n",
    "        detections_array = np.array(all_detections)\n",
    "\n",
    "        # Extract boxes and scores for NMS\n",
    "        boxes = detections_array[:, :4]\n",
    "        scores = detections_array[:, 4]\n",
    "\n",
    "        # Apply NMS using OpenCV\n",
    "        indices = cv2.dnn.NMSBoxes(\n",
    "            boxes.tolist(),\n",
    "            scores.tolist(),\n",
    "            conf_threshold,\n",
    "            NMS_THRESHOLD\n",
    "        )\n",
    "\n",
    "        if len(indices) > 0:\n",
    "            final_detections = detections_array[indices.flatten()]\n",
    "            print(f\"Final detections after NMS: {len(final_detections)}\")\n",
    "            return final_detections.tolist()\n",
    "\n",
    "    print(\"No detections found\")\n",
    "    return []\n",
    "\n",
    "def visualize_tiled_detections(image_path, detections, save_path=None):\n",
    "    \"\"\"\n",
    "    Visualize detections on the full-size image with confidence-based color coding\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = Image.open(image_path)\n",
    "    img_np = np.array(image)\n",
    "\n",
    "    # Create figure\n",
    "    fig, ax = plt.subplots(1, figsize=(15, 15))\n",
    "    ax.imshow(img_np)\n",
    "\n",
    "    # Count detections by confidence level\n",
    "    high_conf = sum(1 for det in detections if det[4] >= 0.7)\n",
    "    med_conf = sum(1 for det in detections if 0.5 <= det[4] < 0.7)\n",
    "    low_conf = sum(1 for det in detections if 0.25 <= det[4] < 0.5)\n",
    "\n",
    "    # Draw detections with confidence-based colors\n",
    "    for detection in detections:\n",
    "        x1, y1, x2, y2, confidence, class_id = detection\n",
    "        width = x2 - x1\n",
    "        height = y2 - y1\n",
    "\n",
    "        # Choose color and label background based on confidence level\n",
    "        if confidence >= 0.7:\n",
    "            edge_color = 'red'\n",
    "            label_color = 'red'\n",
    "            conf_level = 'HIGH'\n",
    "        elif confidence >= 0.5:\n",
    "            edge_color = 'orange'\n",
    "            label_color = 'orange'\n",
    "            conf_level = 'MED'\n",
    "        else:  # confidence >= 0.25\n",
    "            edge_color = 'yellow'\n",
    "            label_color = 'gold'\n",
    "            conf_level = 'LOW'\n",
    "\n",
    "        # Create rectangle with confidence-based color\n",
    "        rect = patches.Rectangle((x1, y1), width, height,\n",
    "                               linewidth=2, edgecolor=edge_color, facecolor='none')\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "        # Add label with confidence level indicator\n",
    "        ax.text(x1, y1-10, f'Aircraft: {confidence:.2f} ({conf_level})',\n",
    "               bbox=dict(facecolor=label_color, alpha=0.7),\n",
    "               color='white', fontsize=10, weight='bold')\n",
    "\n",
    "    # Enhanced title with confidence breakdown\n",
    "    title = f'Tiled Inference Results: {os.path.basename(image_path)}\\n'\n",
    "    title += f'Total: {len(detections)} detections '\n",
    "    title += f'(High≥0.7: {high_conf}, Med≥0.5: {med_conf}, Low≥0.25: {low_conf})'\n",
    "\n",
    "    ax.set_title(title, fontsize=12, pad=20)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add legend\n",
    "    from matplotlib.lines import Line2D\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], color='red', lw=2, label='High Confidence (≥0.7)'),\n",
    "        Line2D([0], [0], color='orange', lw=2, label='Medium Confidence (0.5-0.7)'),\n",
    "        Line2D([0], [0], color='yellow', lw=2, label='Low Confidence (0.25-0.5)')\n",
    "    ]\n",
    "    ax.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.98, 0.98))\n",
    "\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "        print(f\"Saved to: {save_path}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"tiled_inference_results\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Process each test image with tiled inference\n",
    "for i, img_path in enumerate(test_images):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing image {i+1}/{len(test_images)}: {os.path.basename(img_path)}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # Run sliding window inference\n",
    "    detections = sliding_window_inference(\n",
    "        img_path,\n",
    "        model,\n",
    "        tile_width=TILE_WIDTH,\n",
    "        tile_height=TILE_HEIGHT,\n",
    "        overlap=TILE_OVERLAP,\n",
    "        conf_threshold=CONF_THRESHOLD\n",
    "    )\n",
    "\n",
    "    # Visualize results\n",
    "    save_path = os.path.join(output_dir, f\"tiled_{os.path.basename(img_path)}\")\n",
    "    visualize_tiled_detections(img_path, detections, save_path)\n",
    "\n",
    "## Comparison: Direct vs Tiled Inference\n",
    "\n",
    "# Compare direct inference vs tiled inference for one image\n",
    "test_image = test_images[0]  # Change this to test different images\n",
    "\n",
    "print(\"=== DIRECT INFERENCE (Original Method) ===\")\n",
    "# Direct inference on full image\n",
    "results_direct = model(test_image, conf=CONF_THRESHOLD)\n",
    "direct_detections = len(results_direct[0].boxes) if len(results_direct[0].boxes) > 0 else 0\n",
    "print(f\"Direct inference detections: {direct_detections}\")\n",
    "\n",
    "print(\"\\n=== TILED INFERENCE (New Method) ===\")\n",
    "# Tiled inference\n",
    "tiled_detections = sliding_window_inference(test_image, model, conf_threshold=CONF_THRESHOLD)\n",
    "print(f\"Tiled inference detections: {len(tiled_detections)}\")\n",
    "\n",
    "print(f\"\\n=== SUMMARY ===\")\n",
    "print(f\"Improvement: {len(tiled_detections) - direct_detections} additional detections\")"
   ],
   "id": "3d31535c7f89368a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Export model to ONNX format\n",
    "model.export(format='onnx', imgsz=512)\n",
    "\n",
    "# Get S3 credentials from environment variables (pre-configured in OpenShift AI)\n",
    "AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "AWS_S3_ENDPOINT = os.getenv('AWS_S3_ENDPOINT')\n",
    "AWS_S3_BUCKET = os.getenv('AWS_S3_BUCKET')\n",
    "AWS_DEFAULT_REGION = os.getenv('AWS_DEFAULT_REGION', 'us-east-1')\n",
    "\n",
    "print(\"S3 Configuration:\")\n",
    "print(f\"Raw Endpoint: {AWS_S3_ENDPOINT}\")\n",
    "print(f\"Bucket: {AWS_S3_BUCKET}\")\n",
    "print(f\"Region: {AWS_DEFAULT_REGION}\")\n",
    "\n",
    "# Fix the endpoint URL - add https:// if missing\n",
    "if AWS_S3_ENDPOINT and not AWS_S3_ENDPOINT.startswith(('http://', 'https://')):\n",
    "    # For internal OpenShift storage, use https://\n",
    "    endpoint_url = f\"https://{AWS_S3_ENDPOINT}\"\n",
    "else:\n",
    "    endpoint_url = AWS_S3_ENDPOINT\n",
    "\n",
    "print(f\"Fixed Endpoint: {endpoint_url}\")\n",
    "\n",
    "# Set up S3 client using environment variables\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "    endpoint_url=endpoint_url,\n",
    "    region_name=AWS_DEFAULT_REGION,\n",
    ")\n",
    "\n",
    "# OpenVINO Model Server configuration\n",
    "bucket_name = AWS_S3_BUCKET\n",
    "model_name = 'airplane-detection'\n",
    "model_version = '1'\n",
    "\n",
    "# Correct OpenVINO Model Server folder structure: models/{model_name}/{version}/model.onnx\n",
    "model_key = f'models/{model_name}/{model_version}/model.onnx'\n",
    "onnx_path = train_path + \"/weights/best.onnx\"\n",
    "\n",
    "print(f\"Uploading model to OpenVINO Model Server structure...\")\n",
    "print(f\"Bucket: {bucket_name}\")\n",
    "print(f\"Model path: {model_key}\")\n",
    "\n",
    "try:\n",
    "    # Upload the ONNX model file\n",
    "    s3_client.upload_file(onnx_path, bucket_name, model_key)\n",
    "    print(f\"✅ Model uploaded to s3://{bucket_name}/{model_key}\")\n",
    "\n",
    "    # Create and upload model configuration file (optional but recommended)\n",
    "    import json\n",
    "    model_config = {\n",
    "        \"model_config_list\": [\n",
    "            {\n",
    "                \"config\": {\n",
    "                    \"name\": model_name,\n",
    "                    \"base_path\": f\"/models/{model_name}\",\n",
    "                    \"model_platform\": \"onnxruntime_onnx\",\n",
    "                    \"model_version_policy\": {\"all\": {}},\n",
    "                    \"instance_group\": [\n",
    "                        {\n",
    "                            \"name\": \"aircraft_detection\",\n",
    "                            \"kind\": \"KIND_CPU\",\n",
    "                            \"count\": 1\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Save config locally first\n",
    "    config_path = \"model_config.json\"\n",
    "    with open(config_path, 'w') as f:\n",
    "        json.dump(model_config, f, indent=2)\n",
    "\n",
    "    # Upload config file\n",
    "    config_key = f'models/{model_name}/{model_version}/config.json'\n",
    "    s3_client.upload_file(config_path, bucket_name, config_key)\n",
    "    print(f\"✅ Config uploaded to s3://{bucket_name}/{config_key}\")\n",
    "\n",
    "    # Create model server configuration for easier deployment\n",
    "    server_config = {\n",
    "        \"model_config_list\": [\n",
    "            {\n",
    "                \"config\": {\n",
    "                    \"name\": model_name,\n",
    "                    \"base_path\": f\"s3://{bucket_name}/models/{model_name}\",\n",
    "                    \"model_platform\": \"onnxruntime_onnx\",\n",
    "                    \"model_version_policy\": {\"all\": {}}\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    server_config_path = \"server_config.json\"\n",
    "    with open(server_config_path, 'w') as f:\n",
    "        json.dump(server_config, f, indent=2)\n",
    "\n",
    "    print(f\"\\n📋 Model Server Configuration created: {server_config_path}\")\n",
    "    print(f\"Use this file to start OpenVINO Model Server with your model\")\n",
    "\n",
    "    # Verify the upload structure\n",
    "    print(f\"\\n🔍 Verifying S3 structure...\")\n",
    "    try:\n",
    "        # List objects in the model directory\n",
    "        response = s3_client.list_objects_v2(\n",
    "            Bucket=bucket_name,\n",
    "            Prefix=f'models/{model_name}/{model_version}/',\n",
    "            Delimiter='/'\n",
    "        )\n",
    "\n",
    "        if 'Contents' in response:\n",
    "            print(\"✅ Files uploaded successfully:\")\n",
    "            for obj in response['Contents']:\n",
    "                print(f\"   📄 {obj['Key']} ({obj['Size']:,} bytes)\")\n",
    "        else:\n",
    "            print(\"⚠️  No files found - upload may have failed\")\n",
    "\n",
    "    except Exception as verify_error:\n",
    "        print(f\"⚠️  Could not verify upload: {verify_error}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Upload failed: {e}\")\n",
    "    print(f\"\\nTroubleshooting:\")\n",
    "    print(f\"1. Check your AWS credentials and permissions\")\n",
    "    print(f\"2. Verify the bucket '{bucket_name}' exists and is accessible\")\n",
    "    print(f\"3. Ensure your S3 endpoint URL is correct\")\n",
    "\n",
    "# Clean up temporary files\n",
    "import os\n",
    "try:\n",
    "    if os.path.exists(\"model_config.json\"):\n",
    "        os.remove(\"model_config.json\")\n",
    "    if os.path.exists(\"server_config.json\"):\n",
    "        # Keep this file for deployment reference\n",
    "        print(f\"\\n📁 Server configuration saved as: server_config.json\")\n",
    "        print(f\"   You can use this file to deploy your model server\")\n",
    "except:\n",
    "    pass\n"
   ],
   "id": "4cc2c0bc115ff8f8"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
